# -*- coding: utf-8 -*-
"""TestingMLModels.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sq065VQMqEYUjOAewan1yeBGk3HTkEn0

# Testing machine learning models

## Import libraries
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install pyspark

import numpy as np
import pandas
import time
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.metrics import classification_report
from sklearn.metrics import f1_score
from IPython.core.display import display
from pyspark.sql import SparkSession
from pyspark.sql.types import FloatType
from pyspark.sql import functions as f
from pyspark.sql import Row
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
from pyspark.ml import Pipeline
from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, NaiveBayes, GBTClassifier
from xgboost.spark import SparkXGBClassifier
from pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator
from pyspark.ml.feature import MinMaxScaler,StandardScaler
from pyspark.ml.pipeline import PipelineModel

sns.set()

spark = SparkSession.builder.appName('PreprocessingData').config("spark.executor.memory","16g").getOrCreate()
spark

"""## Read dataset"""

from google.colab import drive
drive.mount('/content/drive')

PATH = "/content/drive/MyDrive/dataset/Data_FL/"

dataset = spark.read.csv(PATH+'Predict_Flight_Delays_2025.csv', header=True, inferSchema=True)
dataset.printSchema()
dataset.show(20,False)
dataset.count()

dataset = dataset.withColumn('DATE', f.split('FL_DATE', ' ')[0]).withColumn('ID', f.concat(f.col('DATE'), f.lit('_'),
                                                                                               f.col('OP_UNIQUE_CARRIER'), f.lit('_'),
                                                                                               f.col('ORIGIN'), f.lit('_'),
                                                                                               f.col('DEST'), f.lit('_'),
                                                                                               f.col('OP_CARRIER_FL_NUM')))
dataset.show(20,False)

data = dataset.select('ID', 'QUARTER', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_UNIQUE_CARRIER',
                      'ORIGIN', 'DEST', 'DISTANCE', 'CRS_DEP_TIME', 'DEP_DELAY')
data.printSchema()
data.show(20,False)
data.count()

data.summary().show()

"""## Prepare data"""

# 0: DEP_DELAY <= 0 <=> Không bị trễ.
data_new = data.withColumn('DEP_DELAY', f.when(f.col('DEP_DELAY')<=0, 0).otherwise(f.col('DEP_DELAY')))
# 1: 0 < DEP_DELAY <= 30 minutes <=> Trễ từ 1 đến 30 phút.
data_new = data_new.withColumn('DEP_DELAY', f.when((f.col('DEP_DELAY')>0) & (f.col('DEP_DELAY')<=30), 1).otherwise(f.col('DEP_DELAY')))
# 2: DEP_DELAY > 30 minutes <=> Trễ hơn 30 phút hoặc hủy chuyến.
data_new = data_new.withColumn('DEP_DELAY', f.when(f.col('DEP_DELAY')>30, 2).otherwise(f.col('DEP_DELAY')))
data_new = data_new.withColumnRenamed('DEP_DELAY', 'LABEL')
data_new = data_new.withColumn('LABEL', f.col('LABEL').cast("INT"))

data_new.printSchema()
data_new.show()

train, test = data_new.randomSplit(weights=[0.8,0.2], seed=2025)

train.printSchema()
train.show()
train.count()

test.printSchema()
test.show()
test.count()

df_train = train.select('LABEL').toPandas()
df_test = test.select('LABEL').toPandas()

label_train = list(df_train.LABEL.value_counts())
label_test = list(df_test.LABEL.value_counts())

rate_train = [round(x * 100 / sum(label_train), 1) for x in label_train]
rate_test = [round(x * 100 / sum(label_test), 1) for x in label_test]

labels = ['G1', 'G2', 'G3']

x = np.arange(len(labels))  # the label locations
width = 0.35  # the width of the bars

fig, ax = plt.subplots(figsize =(12, 8))
rects1 = ax.bar(x - width/2, label_train, width, label='Train set', color ='#00BFFF')
rects2 = ax.bar(x + width/2, label_test, width, label='Test set', color ='#00FFFF')
ax = plt.gca()
ax.ticklabel_format(useOffset=False, style='plain')
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()

def autolabel_train(rects):
    i = 0
    for rect in rects:
        height = rect.get_height()
        height_2 = str(rate_train[i]) + '%'
        i = i + 1
        ax.annotate('{}'.format(height_2),
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # 3 points vertical offset
                    textcoords="offset points",
                    ha='center', va='bottom')
def autolabel_test(rects):
    i = 0
    for rect in rects:
        height = rect.get_height()
        height_2 = str(rate_test[i]) + '%'
        i = i + 1
        ax.annotate('{}'.format(height_2),
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # 3 points vertical offset
                    textcoords="offset points",
                    ha='center', va='bottom')

autolabel_train(rects1)
autolabel_test(rects2)
# Adding Xticks
plt.xlabel('Label', fontsize = 15, fontfamily='serif')
plt.ylabel('Count', fontsize = 15, fontfamily='serif')

fig.tight_layout()
plt.show()

"""## Build and evaluate models

### Logistic regression

#### Training model
"""

stringIndexer = StringIndexer(inputCols=['OP_UNIQUE_CARRIER', 'ORIGIN', 'DEST'],
                              outputCols=['OP_UNIQUE_CARRIERIndex', 'ORIGINIndex', 'DESTIndex'])

oneHotEncoder = OneHotEncoder(inputCols=['OP_UNIQUE_CARRIERIndex', 'ORIGINIndex', 'DESTIndex'],
                              outputCols=['OP_UNIQUE_CARRIERVec', 'ORIGINVec','DESTVec'])

assembler = VectorAssembler(inputCols=['QUARTER', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_UNIQUE_CARRIERVec', 'ORIGINVec',
                                       'DESTVec', 'DISTANCE', 'CRS_DEP_TIME'], outputCol='features')

# scaler = StandardScaler(inputCol="features", outputCol="scaledFeatures")

LR = LogisticRegression(featuresCol='features',
                        # featuresCol = 'scaledFeatures'
                        labelCol='LABEL')

pipeline = Pipeline(stages=[stringIndexer,
                            oneHotEncoder,
                            assembler,
                            # scaler,
                            LR])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model_LR = pipeline.fit(train)

"""#### Evaluate model

##### Train
"""

Trained = model_LR.transform(train)
Trained.show(truncate=False)
Trained.count()

Trained.select('prediction').groupBy('prediction').count().show()

predicted_train = Trained.select("prediction", 'LABEL')
predicted_train_score = predicted_train.toPandas()

print(classification_report(predicted_train_score.LABEL,
                            predicted_train_score.prediction,
                            target_names=['0', '1', '2'], digits=4))

evaluator = MulticlassClassificationEvaluator(labelCol='LABEL', metricName='accuracy')
accuracy_train = evaluator.evaluate(Trained)
f1_mic = f1_score(predicted_train_score['LABEL'],
                  predicted_train_score['prediction'],
                  average = 'micro')
f1_mac = f1_score(predicted_train_score['LABEL'],
                  predicted_train_score['prediction'],
                  average = 'macro')

print('='*15+'Training Data'+'='*15)
print(f'Accuracy: {accuracy_train*100:.5f}%')
print(f'F1-Micro: {f1_mic*100:.5f}%')
print(f'F1-Macro: {f1_mac*100:.5f}%')

"""##### Test"""

Tested = model_LR.transform(test)
Tested.show()
Tested.count()

Tested.select('prediction').groupBy('prediction').count().show()

predicted_test = Tested.select("prediction", 'LABEL')
predicted_test_score = predicted_test.toPandas()

from sklearn.metrics import classification_report
print(classification_report(predicted_test_score.LABEL,
                            predicted_test_score.prediction,
                            target_names=['0', '1', '2'], digits=4))

evaluator = MulticlassClassificationEvaluator(labelCol='LABEL', metricName='accuracy')
accuracy_test = evaluator.evaluate(Tested)
f1_mic = f1_score(predicted_test_score['LABEL'],
                  predicted_test_score['prediction'],
                  average = 'micro')
f1_mac = f1_score(predicted_test_score['LABEL'],
                  predicted_test_score['prediction'],
                  average = 'macro')

print('='*15+'Testing Data'+'='*15)
print(f'Accuracy: {accuracy_test*100:.5f}%')
print(f'F1-Micro: {f1_mic*100:.5f}%')
print(f'F1-Macro: {f1_mac*100:.5f}%')

"""#### Save & load model"""

model_LR.write().overwrite().save('/content/drive/MyDrive/dataset/Model/LR')

model_LR_load = PipelineModel.load('/content/drive/MyDrive/dataset/Model/LR')

"""### Decision tree

#### Training model
"""

stringIndexer = StringIndexer(inputCols=['OP_UNIQUE_CARRIER', 'ORIGIN', 'DEST'],
                              outputCols=['OP_UNIQUE_CARRIERIndex', 'ORIGINIndex', 'DESTIndex'])

oneHotEncoder = OneHotEncoder(inputCols=['OP_UNIQUE_CARRIERIndex', 'ORIGINIndex', 'DESTIndex'],
                              outputCols=['OP_UNIQUE_CARRIERVec', 'ORIGINVec','DESTVec'])

assembler = VectorAssembler(inputCols=['QUARTER', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_UNIQUE_CARRIERVec', 'ORIGINVec',
                                       'DESTVec', 'DISTANCE', 'CRS_DEP_TIME'], outputCol='features')

# scaler = StandardScaler(inputCol="features", outputCol="scaledFeatures")

DT = DecisionTreeClassifier(maxDepth=16, featuresCol='features', labelCol='LABEL')

pipeline = Pipeline(stages=[stringIndexer,
                            oneHotEncoder,
                            assembler, DT])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model_DT = pipeline.fit(train)

"""#### Evaluate model

##### Train
"""

Trained = model_DT.transform(train)
Trained.show()
Trained.count()

Trained.select('prediction').groupBy('prediction').count().show()

predicted_train = Trained.select("prediction", 'LABEL')
predicted_train_score = predicted_train.toPandas()

print(classification_report(predicted_train_score.LABEL,
                            predicted_train_score.prediction,
                            target_names=['0', '1', '2'], digits=4))

evaluator = MulticlassClassificationEvaluator(labelCol='LABEL', metricName='accuracy')
accuracy_train = evaluator.evaluate(Trained)
f1_mic = f1_score(predicted_train_score['LABEL'],
                  predicted_train_score['prediction'],
                  average = 'micro')
f1_mac = f1_score(predicted_train_score['LABEL'],
                  predicted_train_score['prediction'],
                  average = 'macro')

print('='*15+'Training Data'+'='*15)
print(f'Accuracy: {accuracy_train*100:.5f}%')
print(f'F1-Micro: {f1_mic*100:.5f}%')
print(f'F1-Macro: {f1_mac*100:.5f}%')

"""##### Test"""

Tested = model_DT.transform(test)
Tested.show()
Tested.count()

Tested.select('prediction').groupBy('prediction').count().show()

predicted_test = Tested.select("prediction", 'LABEL')
predicted_test_score = predicted_test.toPandas()

from sklearn.metrics import classification_report
print(classification_report(predicted_test_score.LABEL,
                            predicted_test_score.prediction,
                            target_names=['0', '1', '2'], digits=4))

evaluator = MulticlassClassificationEvaluator(labelCol='LABEL', metricName='accuracy')
accuracy_test = evaluator.evaluate(Tested)
f1_mic = f1_score(predicted_test_score['LABEL'],
                  predicted_test_score['prediction'],
                  average='micro')
f1_mac = f1_score(predicted_test_score['LABEL'],
                  predicted_test_score['prediction'],
                  average='macro')

print('='*15+'Testing Data'+'='*15)
print(f'Accuracy: {accuracy_test*100:.5f}%')
print(f'F1-Micro: {f1_mic*100:.5f}%')
print(f'F1-Macro: {f1_mac*100:.5f}%')

"""#### Save & load model"""

model_DT.write().overwrite().save('/content/drive/MyDrive/dataset/Model/DT')

model_DT_load = PipelineModel.load('/content/drive/MyDrive/dataset/Model/DT')

import shutil
import os

# Define the path to the models directory
models_dir = '/content/drive/MyDrive/dataset/Model'

# Define the output path for the zip file in the content directory
output_zip_path = '/content/Models'

# Create a zip archive of the models directory
shutil.make_archive(output_zip_path, 'zip', models_dir)

print(f"Models successfully zipped to {output_zip_path}.zip")
print("You can now download this file from the Colab file browser (left panel) or use the following command:")
print("!cp /content/Models.zip /content/drive/MyDrive/")

"""### Random forest

#### Training model
"""

stringIndexer = StringIndexer(inputCols=['OP_UNIQUE_CARRIER', 'ORIGIN', 'DEST'],
                              outputCols=['OP_UNIQUE_CARRIERIndex', 'ORIGINIndex', 'DESTIndex'])

oneHotEncoder = OneHotEncoder(inputCols=['OP_UNIQUE_CARRIERIndex', 'ORIGINIndex', 'DESTIndex'],
                              outputCols=['OP_UNIQUE_CARRIERVec', 'ORIGINVec','DESTVec'])

assembler = VectorAssembler(inputCols=['QUARTER', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_UNIQUE_CARRIERVec', 'ORIGINVec',
                                       'DESTVec', 'DISTANCE', 'CRS_DEP_TIME'], outputCol='features')

# scaler = StandardScaler(inputCol="features", outputCol="scaledFeatures")

RF = RandomForestClassifier(maxDepth=10, numTrees = 3, featuresCol='features', labelCol='LABEL')#

pipeline = Pipeline(stages=[stringIndexer,
                            oneHotEncoder,
                            assembler, RF])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model_RF = pipeline.fit(train)

"""#### Evaluate model

##### Train
"""

Trained = model_RF.transform(train)
Trained.show()
Trained.count()

Trained.select('prediction').groupBy('prediction').count().show()

predicted_train = Trained.select("prediction", 'LABEL')
predicted_train_score = predicted_train.toPandas()

print(classification_report(predicted_train_score.LABEL,
                            predicted_train_score.prediction,
                            target_names=['0', '1', '2'], digits=4))

evaluator = MulticlassClassificationEvaluator(labelCol='LABEL', metricName='accuracy')
accuracy_train = evaluator.evaluate(Trained)
f1_mic = f1_score(predicted_train_score['LABEL'],
                  predicted_train_score['prediction'],
                  average = 'micro')
f1_mac = f1_score(predicted_train_score['LABEL'],
                  predicted_train_score['prediction'],
                  average = 'macro')

print('='*15+'Training Data'+'='*15)
print(f'Accuracy: {accuracy_train*100:.5f}%')
print(f'F1-Micro: {f1_mic*100:.5f}%')
print(f'F1-Macro: {f1_mac*100:.5f}%')

"""##### Test"""

Tested = model_RF.transform(test)
Tested.show()
Tested.count()

Tested.select('prediction').groupBy('prediction').count().show()

predicted_test = Tested.select("prediction", 'LABEL')
predicted_test_score = predicted_test.toPandas()

from sklearn.metrics import classification_report
print(classification_report(predicted_test_score.LABEL,
                            predicted_test_score.prediction,
                            target_names=['0', '1', '2'], digits=4))

evaluator = MulticlassClassificationEvaluator(labelCol='LABEL', metricName='accuracy')
accuracy_test = evaluator.evaluate(Tested)
f1_mic = f1_score(predicted_test_score['LABEL'],
                  predicted_test_score['prediction'],
                  average = 'micro')
f1_mac = f1_score(predicted_test_score['LABEL'],
                  predicted_test_score['prediction'],
                  average = 'macro')

print('='*15+'Testing Data'+'='*15)
print(f'Accuracy: {accuracy_test*100:.5f}%')
print(f'F1-Micro: {f1_mic*100:.5f}%')
print(f'F1-Macro: {f1_mac*100:.5f}%')

"""#### Save & load model"""

model_RF.write().overwrite().save('/content/drive/MyDrive/dataset/Model/RF')

model_RF_load = PipelineModel.load('/content/drive/MyDrive/dataset/Model/RF')

"""### Naive Bayes

#### Training model
"""

stringIndexer = StringIndexer(inputCols=['OP_UNIQUE_CARRIER', 'ORIGIN', 'DEST'],
                              outputCols=['OP_UNIQUE_CARRIERIndex', 'ORIGINIndex', 'DESTIndex'])

oneHotEncoder = OneHotEncoder(inputCols=['OP_UNIQUE_CARRIERIndex', 'ORIGINIndex', 'DESTIndex'],
                              outputCols=['OP_UNIQUE_CARRIERVec', 'ORIGINVec','DESTVec'])

assembler = VectorAssembler(inputCols=['QUARTER', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_UNIQUE_CARRIERVec', 'ORIGINVec',
                                       'DESTVec', 'DISTANCE', 'CRS_DEP_TIME'], outputCol='features')

# scaler = StandardScaler(inputCol="features", outputCol="scaledFeatures")

NB = NaiveBayes(featuresCol='features', labelCol='LABEL', smoothing=0.0003, modelType="multinomial")

pipeline = Pipeline(stages=[stringIndexer,
                            oneHotEncoder,
                            assembler, NB])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model_NB = pipeline.fit(train)

"""#### Evaluate model

##### Train
"""

Trained = model_NB.transform(train)
Trained.show()
Trained.count()

Trained.select('prediction').groupBy('prediction').count().show()

predicted_train = Trained.select("prediction", 'LABEL')
predicted_train_score = predicted_train.toPandas()

print(classification_report(predicted_train_score.LABEL,
                            predicted_train_score.prediction,
                            target_names=['0', '1', '2'], digits=4))

evaluator = MulticlassClassificationEvaluator(labelCol='LABEL', metricName='accuracy')
accuracy_train = evaluator.evaluate(Trained)
f1_mic = f1_score(predicted_train_score['LABEL'],
                  predicted_train_score['prediction'],
                  average = 'micro')
f1_mac = f1_score(predicted_train_score['LABEL'],
                  predicted_train_score['prediction'],
                  average = 'macro')

print('='*15+'Training Data'+'='*15)
print(f'Accuracy: {accuracy_train*100:.5f}%')
print(f'F1-Micro: {f1_mic*100:.5f}%')
print(f'F1-Macro: {f1_mac*100:.5f}%')

"""##### Test"""

Tested = model_NB.transform(test)
Tested.show()
Tested.count()

Tested.select('prediction').groupBy('prediction').count().show()

predicted_test = Tested.select("prediction", 'LABEL')
predicted_test_score = predicted_test.toPandas()

from sklearn.metrics import classification_report
print(classification_report(predicted_test_score.LABEL,
                            predicted_test_score.prediction,
                            target_names=['0', '1', '2'], digits=4))

evaluator = MulticlassClassificationEvaluator(labelCol='LABEL', metricName='accuracy')
accuracy_test = evaluator.evaluate(Tested)
f1_mic = f1_score(predicted_test_score['LABEL'],
                  predicted_test_score['prediction'],
                  average = 'micro')
f1_mac = f1_score(predicted_test_score['LABEL'],
                  predicted_test_score['prediction'],
                  average = 'macro')

print('='*15+'Testing Data'+'='*15)
print(f'Accuracy: {accuracy_test*100:.5f}%')
print(f'F1-Micro: {f1_mic*100:.5f}%')
print(f'F1-Macro: {f1_mac*100:.5f}%')

"""#### Save & load model"""

model_NB.write().overwrite().save('/content/drive/MyDrive/dataset/Model/NB')

model_NB_load = PipelineModel.load('/content/drive/MyDrive/dataset/Model/NB')

"""### XGBoost

#### Training model
"""

stringIndexer = StringIndexer(inputCols=['OP_UNIQUE_CARRIER', 'ORIGIN', 'DEST'],
                              outputCols=['OP_UNIQUE_CARRIERIndex', 'ORIGINIndex', 'DESTIndex'])

oneHotEncoder = OneHotEncoder(inputCols=['OP_UNIQUE_CARRIERIndex', 'ORIGINIndex', 'DESTIndex'],
                              outputCols=['OP_UNIQUE_CARRIERVec', 'ORIGINVec','DESTVec'])

assembler = VectorAssembler(inputCols=['QUARTER', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_UNIQUE_CARRIERVec', 'ORIGINVec',
                                       'DESTVec', 'DISTANCE', 'CRS_DEP_TIME'], outputCol='features')

XGB = SparkXGBClassifier(features_col='features', label_col='LABEL')

pipeline = Pipeline(stages=[stringIndexer,
                                    oneHotEncoder,
                                    assembler,
                                    XGB])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model_XGB = pipeline.fit(train)

"""#### Evaluate model

##### Train
"""

Trained_xgb = model_XGB.transform(train)
Trained_xgb.show()
Trained_xgb.count()

Trained_xgb.select('prediction').groupBy('prediction').count().show()

predicted_train_xgb = Trained_xgb.select("prediction", 'LABEL')
predicted_train_score_xgb = predicted_train_xgb.toPandas()

print(classification_report(predicted_train_score_xgb.LABEL,
                            predicted_train_score_xgb.prediction,
                            target_names=['0', '1', '2'], digits=4))

evaluator = MulticlassClassificationEvaluator(labelCol='LABEL', metricName='accuracy')
accuracy_train = evaluator.evaluate(Trained_xgb)
f1_mic = f1_score(predicted_train_score_xgb['LABEL'],
                  predicted_train_score_xgb['prediction'],
                  average = 'micro')
f1_mac = f1_score(predicted_train_score_xgb['LABEL'],
                  predicted_train_score_xgb['prediction'],
                  average = 'macro')

print('='*15+'Training Data'+'='*15)
print(f'Accuracy: {accuracy_train*100:.5f}%')
print(f'F1-Micro: {f1_mic*100:.5f}%')
print(f'F1-Macro: {f1_mac*100:.5f}%')

"""##### Test"""

Tested_xgb = model_XGB.transform(test)
Tested_xgb.show()
Tested_xgb.count()

Tested_xgb.select('prediction').groupBy('prediction').count().show()

predicted_test_xgb = Tested_xgb.select("prediction", 'LABEL')
predicted_test_score_xgb = predicted_test_xgb.toPandas()

from sklearn.metrics import classification_report
print(classification_report(predicted_test_score_xgb.LABEL,
                            predicted_test_score_xgb.prediction,
                            target_names=['0', '1', '2'], digits=4))

evaluator = MulticlassClassificationEvaluator(labelCol='LABEL', metricName='accuracy')
accuracy_test = evaluator.evaluate(Tested_xgb)
f1_mic = f1_score(predicted_test_score_xgb['LABEL'],
                  predicted_test_score_xgb['prediction'],
                  average = 'micro')
f1_mac = f1_score(predicted_test_score_xgb['LABEL'],
                  predicted_test_score_xgb['prediction'],
                  average = 'macro')

print('='*15+'Testing Data'+'='*15)
print(f'Accuracy: {accuracy_test*100:.5f}%')
print(f'F1-Micro: {f1_mic*100:.5f}%')
print(f'F1-Macro: {f1_mac*100:.5f}%')

"""#### Save & load model"""

model_XGB.write().overwrite().save('/content/drive/MyDrive/dataset/Model/XGB')

model_XGB_load = PipelineModel.load('/content/drive/MyDrive/dataset/Model/XGB')